#+TITLE: Optimal compounding with penalties
#+CREATED: [2021-11-13 Sat 00:07]
#+LAST_MODIFIED: [2022-01-08 Sat 00:25]
#+ROAM_TAGS: money composition
#+STARTUP: showall indent
#+OPTIONS: toc:nil
#+OPTIONS: tex:t
#+OPTIONS: ^:nil p:nil

#+HUGO_BASE_DIR: ./
#+hugo_front_matter_format: yaml
#+HUGO_CUSTOM_FRONT_MATTER: :date (org-to-blog-date (org-global-prop-value "CREATED"))
#+HUGO_CUSTOM_FRONT_MATTER: :hero ./images/hero.jpg
#+HUGO_CUSTOM_FRONT_MATTER: :secret false
#+HUGO_CUSTOM_FRONT_MATTER: :excerpt Making money with your money's money

* Forward for the author                                           :noexport:

This post has a heavy focus on technical literate programming. This documents
goal is too produce two products. One for the author/developer and one for the
reader. The author's version gets to view the document in full, while the
reader's view is only the exported version. The explicit pieces that not
exported (and therefore hidden from the reader's view) are those which are not
directly relevant to the content of the article. This includes tools for the
author, exporting functionality, tests, configuration, etc.

** Exporting

#+BEGIN_SRC emacs-lisp :exports none
  ;; All inline code blocks will be latex
  (setq org-babel-inline-result-wrap "$%s$")

  ;; Configure languages
  (org-babel-do-load-languages
   'org-babel-load-languages
   '((shell . t)
     (python . t)))

  (defun org-hugo-link (link contents info) (org-md-link link contents info))

  ;; Setup org/latex exporting
  (add-to-list 'org-export-filter-latex-fragment-functions
               'sub-paren-for-dollar-sign)
  (add-to-list 'org-export-filter-headline-functions
               'remove-regexp-curly-braces)
  (add-to-list 'org-export-filter-latex-environment-functions
               'sub-paren-for-dollar-sign)
  (export-to-mdx-on-save)
#+END_SRC

#+RESULTS:
: Enabled mdx on save

** Configuration

The primary language we will be using is python inside of a container, org mode
(with TRAMP) has the fantastic feature of being able to execute src code blocks
inside a container which we will be leveraging for this post to the purpose of
isolation.

#+CONSTANTS: image_name=compounder container_name=compounder

#+NAME: container-dir-str
#+HEADER: :exports none
#+begin_src emacs-lisp
  (setq shutdown-env nil)
  (setq docker-tramp-docker-executable "podman")
  (docker-tramp-add-method)
  (setq ob-ipython-command "ipython")
  ;;(setq org-babel-python-command "ipython --no-banner --classic --no-confirm-exit")
  (setq org-babel-python-command "ipython")
  (setq py-default-interpreter "ipython")
  (setq container-dir-str (format "/docker:sage@%s:/mnt" (org-table-get-constant "container_name")))
#+end_src

#+RESULTS: container-dir-str
: /docker:sage@compounder:/mnt

** Environment setup

As mentioned we will be running the following code inside a container. Here we
setup our base container as sagemath, install some necessary package, and a
interactive python session with the starting variables

#+NAME: compounder-environment-build
#+HEADER: :exports code :padline no
#+BEGIN_SRC podman-build :dir "." :tangle (make-temp-name "Dockerfile-") :tag (org-table-get-constant "image_name")
  FROM sagemath/sagemath:latest
  USER root
  ENV DEBIAN_FRONTEND=noninteractive
  RUN apt-get update && \
      apt install vtk7 libvtk7-dev cmake -y && \
      rm -rf /var/lib/apt/lists/*
  USER sage
  RUN sage -python3 -m pip install sympy_plot_backends kaleido cvxpy
  RUN echo "$(date): Done!"
#+END_SRC

#+RESULTS: compounder-environment-build
: #<window 16 on /tmp/babel-Q4ntqo/ob-podman-build-out-zcRgWa>

#+NAME: compounder-environment-start
#+HEADER: :exports none
#+begin_src bash :results verbatim :var NAME=(org-table-get-constant "container_name")
  echo "Running container if not already running ..."
  [ ! "$(podman ps | grep $NAME)" ] && \
    (podman run \
           -d \
           -u $(id -u):$(id -g) \
           --userns keep-id \
           --name $NAME \
           --rm \
           --net host \
           -v $(pwd):/mnt \
           -w /mnt \
           -it compounder:latest; \
    echo "Container starting...") \
    || \
    echo "Container already running..."
#+end_src

#+RESULTS: compounder-environment-start
: Running container if not already running ...
: Container already running...

#+NAME: init
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
print("init")
#+END_SRC

#+RESULTS: init
: init

* Cryptocurrency "dividends"? ðŸ¤”

Most people who are "in the know" of the cryptocurrency/defi world have probably
heard of the various ways to earn "dividends" from their holdings. By leveraging
earning protocols such as staking, lending, or by being a liquidity provider,
people can just sit back and accrue tokens, increasing their portfolio's
value. This is starkly different from the norm, which is to HODL until the price
of their assets hits the moon.

Unlike those who strictly HODL, earners that continually invest their returns
back into earning protocols benefit from the :sparkles:magic:sparkles: that is
compound interest.

Unfortunately, since most cryptocurrency/blockchain projects are pay to play
(due to gas fees), every time an earner wants to interact with an earning
protocol, they need to pay a fee to do so. In short: You need to spend tokens to
make tokens ...

This begs the question: How do we spend the least to make the most with respect
to these earning protocols and compound interest?

* Abstracting earning protocols

There are many methods to earn "dividends" from cryptocurrency; however, most
fall into one of two types:

1. Auto compounding
2. Manual compounding

Auto compounding earning protocols will compound frequently and automatically,
but usually do so for a percentage fee of your earnings. Manual compounding
earning protocols, instead, require *you* to compound your own earnings, only
having to pay for gas fees.

Despite both flavors, they both intend for you to follow the same steps:

1. Deposit tokens into the earning protocol
2. Wait for "dividends" to accrue
3. Receive/claim "dividends"

It might seem obvious at first just to choose the auto compounding type as it's
simpler and easier, but just because it seems obvious *does not* mean it's the
most profitable.

Instead of blindly following this procedure, let's take a closer look at both of
these types of earning protocols and see if we can come up with an expression to
model potential earnings. This will allow us to better understand the
differences between both types and be better informed before investing in one of
them.

To start, let's abstract out some overarching parameters (since most earning
protocols can be modeled similarly to one another).

#+NAME: compounder-session-start
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  import sympy
  from sage.all import *
  from sage.plot.plot3d.plot3d import axes
  from sage.numerical.optimize import minimize
  from sage.manifolds.utilities import set_axes_labels

  P, r, i, n, t = var("P r i n t")
  f = var("f", latex_name="f_{gas}")
  f_p = var("f_p", latex_name="f_{perc}")
  Ps = var('P', n=5)
  Pn = var('P_n', latex_name="P_n")
  Pn1 = var('P_n1', latex_name="P_{n-1}")
  assume(P > 0)
  assume(f > 0)
  assume(r > 0)
  print("Params initialized ...")

  latex_center = lambda expr: \
    '\n' + \
    LatexExpr("\\begin{alignedat}{2}") + \
    '\n' + \
    expr + \
    '\n' + \
    LatexExpr("\\end{alignedat}") + \
    '\n'

  latex_centers = lambda *exprs: \
    '\n' + \
    LatexExpr("\\begin{alignedat}{2}") + \
    '\n' + \
    ' \\\\ '.join(exprs) + \
    ' \n' + \
    LatexExpr("\\end{alignedat}") + \
    '\n'

  latex_right = lambda a, b: a + LatexExpr(" \\rightarrow ") + b

  latex_lim = lambda expr, a, b: \
    LatexExpr("\\lim\\limits_{") + \
    a + \
    LatexExpr("\\rightarrow") + \
    b + \
    LatexExpr("}") + \
    expr
#+END_SRC

#+RESULTS[97baf44d19a33f07bad8a57c3399bba81473e8b2]: compounder-session-start
: Params initialized ...

- src_python[:results output :session :dir (org-sbe
  container-dir-str)]{print(latex(t))} {{{results(t)}}} - Time until each
  compound (in years)
- src_python[:results output :session :dir (org-sbe
  container-dir-str)]{print(latex(n))} {{{results(n)}}} - Number of compounds
  per year
- src_python[:results output :session :dir (org-sbe
  container-dir-str)]{print(latex(P))} {{{results($P$)}}} - Initial balance
- src_python[:results output :session :dir (org-sbe
  container-dir-str)]{print(latex(r))} {{{results($r$)}}} - APR
- src_python[:results output :session :dir (org-sbe
  container-dir-str)]{print("$f$")} {{{results($$f$$)}}} - Fee per compound

#+begin_quote
*Aside* - We will assume, in the manual compounding case, that every time earnings
are "claimed," they are automatically reinvested back into the protocol,
effectively making it a compounding process.
#+end_quote

* Modeling auto compounding

Although most auto compounding earning protocols charge a fee, they have the
nice added benefit of zero interaction. We can sit back and stack tokens knowing
everything is managed for us. Predicting our future earnings in this category is
simple as we can model future earnings with the compound interest formula (with
some modifications):

#+NAME: auto-compounding-interest
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  compound_interest_with_auto_fee = ( P * ( 1 + ( r / n ) - (f_p/n) ) ** (n*t) )
  print(latex_center(latex(compound_interest_with_auto_fee)))
#+END_SRC

#+RESULTS: auto-compounding-interest
:
:  \begin{alignedat}{2}
:  P {\left(-\frac{{f_{perc}}}{n} + \frac{r}{n} + 1\right)}^{n t}
:  \end{alignedat}

#+MACRO: auto-compounding-interest (eval (latex-display-wrap (org-sbe auto-compounding-interest)))

{{{auto-compounding-interest()}}}

As long as we take into account the percentage fee and APR, calculating future
earnings is simple and direct.

* Modeling Manual compounding

Manual compounding earning protocols are more nuanced when calculating potential
earnings than their auto counterparts (and are the primary focus of this
post). Since we compound at our own schedule, we get to choose how fast or slow
we want to do so. The obvious next question to ask is, "what is the best
compounding schedule?" But before we get there, let's start from square one and
create an expression to model earnings after compounding just once:

#+NAME: earning-over-time-1
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_centers(
          latex(Ps[0] + (Ps[0]*r*t) - f == Ps[1])
      )
  )
#+END_SRC

#+RESULTS: earning-over-time-1
:
:  \begin{alignedat}{2}
:  P_{0} r t + P_{0} - f = P_{1}
:  \end{alignedat}

#+MACRO: earning-over-time-1 (eval (latex-display-wrap (org-sbe earning-over-time-1)))

{{{earning-over-time-1()}}}

This is our base case where src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(Ps[0]))} is our initial balance and
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(Ps[1]))} is our balance after compounding. Now
the obvious next question is what does this expression look like if we compound
again? Compounding for a second time means we follow the same formula as before,
except we substitute our second balance with our balance *after* the first
compound. We will also assume our compounding schedule is at a constant rate,
represented by time src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(t))} between compounds. This can be described as
follows:

#+NAME: earning-over-time-2
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_centers(
          latex(Ps[0] + (Ps[0]*r*t) - f == Ps[1]),
          latex(Ps[1] + (Ps[1]*r*t) - f == Ps[2]),
          latex((Ps[0] + (Ps[0]*r*t) - f + ((Ps[0] + (Ps[0]*r*t) - f)*r*t) - f).simplify_full() == Ps[2])
      )
  )
#+END_SRC

#+RESULTS: earning-over-time-2
:
:  \begin{alignedat}{2}
:  P_{0} r t + P_{0} - f = P_{1} \\ P_{1} r t + P_{1} - f = P_{2} \\ P_{0} r^{2} t^{2} + {\left(2 \, P_{0} - f\right)} r t + P_{0} - 2 \, f = P_{2}
:  \end{alignedat}

#+MACRO: earning-over-time-2 (eval (latex-display-wrap (org-sbe earning-over-time-2)))

{{{earning-over-time-2()}}}

Now if we want to compound many times, we can define our future balance
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(Pn))} recursively as follows:

#+NAME: earning-over-time-n
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_centers(
          latex(Ps[0] + (Ps[0]*r*t) - f == Ps[1]),
          latex(Pn1 + (Pn1*r*t) - f == Pn),
      )
  )
#+END_SRC

#+RESULTS: earning-over-time-n
:
:  \begin{alignedat}{2}
:  P_{0} r t + P_{0} - f = P_{1} \\ {P_{n-1}} r t + {P_{n-1}} - f = {P_n}
:  \end{alignedat}

#+MACRO: earning-over-time-n (eval (latex-display-wrap (org-sbe earning-over-time-n)))

{{{earning-over-time-n()}}}

This recursive definition is great! But it would be nicer (and simpler to
compute) if we had a closed form expression. Backing up to the
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n==2))} case, if we re-arrange a few of the
terms, and substitute src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(t==1/n))} {{{results(t = \frac{1}{n})}}}, we can
start to see a familiar formula appear:

#+NAME: n2-compound-interest
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
   formulur1 = Ps[0] + (Ps[0]*r*t) - f + ((Ps[0] + (Ps[0]*r*t) - f)*r*t) - f
   formulur2 = Ps[0]*(r*t + 1)**2 - f*r*t - 2*f
   formulur3 = Ps[0]*((r*Rational("1/2")).mul(1,hold=True) + 1)**2 - (f*r*Rational("1/2")).mul(1,hold=True) - 2*f
   assert bool(formulur1==formulur2)
   print(
       latex_centers(
           latex(formulur1),
           latex(formulur2),
           latex(formulur3)
       ).replace("=","&= \\\\")
   )
#+END_SRC

#+RESULTS: n2-compound-interest
:
:  \begin{alignedat}{2}
:  {\left(P_{0} r t + P_{0} - f\right)} r t + P_{0} r t + P_{0} - 2 \, f \\ {\left(r t + 1\right)}^{2} P_{0} - f r t - 2 \, f \\ P_{0} {\left(\left(\frac{1}{2} \, r\right) + 1\right)}^{2} - \frac{1}{2} \, f r - 2 \, f
:  \end{alignedat}

#+MACRO: n2-compound-interest (eval (latex-display-wrap (org-sbe n2-compound-interest)))

{{{n2-compound-interest()}}}

Looking closely at the final expression, we can see that the leftmost component
looks eerily like compound interest. That's because it is! And if we compare the
formula for compound interest against this term we can see that there is a
direct comparison that will be embedded for every positive src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex(n))}.

#+NAME: compound-interest
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  compound_interest = ( P * ( 1 + ( r / n ) ) ** n )
  compound_interest_latex = latex_center(latex(compound_interest))
  print(compound_interest_latex)
#+END_SRC

#+RESULTS: compound-interest
:
:  \begin{alignedat}{2}
:  P {\left(\frac{r}{n} + 1\right)}^{n}
:  \end{alignedat}

#+MACRO: compound-interest (eval (latex-display-wrap (org-sbe compound-interest)))

{{{compound-interest()}}}

Now this is all well and good, but there are additional terms we aren't
accounting for related to the fees that are paid each compounding. This can be
expressed via the idea of iterative penalties which is the summation of fees
subtracted from each compounding instance.

#+NAME: iterative-penalty
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
iterative_penalty = ( f * sum( (1 + (r / n))**i , i, 0, n-1, hold=True) )
print(latex_center(latex(iterative_penalty)))
#+END_SRC

#+RESULTS: iterative-penalty
:
:  \begin{alignedat}{2}
:  f {\sum_{i=0}^{n - 1} {\left(\frac{r}{n} + 1\right)}^{i}}
:  \end{alignedat}

#+MACRO: iterative-penalty (eval (latex-display-wrap (org-sbe iterative-penalty)))

{{{iterative-penalty()}}}

By subtracting the iterative penalty fees from compound interest, we get the
following expression which is equivalent to our recursive definition:

#+NAME: compound-interest-with-iterative-penalty-verbose
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  compound_interest_with_iterative_penalty = compound_interest - iterative_penalty
  print(latex_center(latex(compound_interest_with_iterative_penalty)))
#+END_SRC

#+NAME: compound-interest-with-iterative-penalty-verbose
#+RESULTS: compound-interest-with-iterative-penalty-verbose
:
:  \begin{alignedat}{2}
:  P {\left(\frac{r}{n} + 1\right)}^{n} - f {\sum_{i=0}^{n - 1} {\left(\frac{r}{n} + 1\right)}^{i}}
:  \end{alignedat}

#+MACRO: compound-interest-with-iterative-penalty-verbose (eval (latex-display-wrap (org-sbe compound-interest-with-iterative-penalty-verbose)))

{{{compound-interest-with-iterative-penalty-verbose()}}}

Simplifying iterative penalties as a geometric series, we arrive at our final
function, compound interest with iterative penalties (or src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex(ciwip))}).

#+NAME: compound-interest-with-iterative-penalty-simple
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  compound_interest_with_iterative_penalty = compound_interest - iterative_penalty.unhold()
  ciwip = function('ciwip')
  print(latex_center(latex(ciwip(P,r,f,n) == compound_interest - iterative_penalty.unhold())))
#+END_SRC

#+RESULTS[92dcf708f6a8d7e37d1096957d942ffc9645a2ff]: compound-interest-with-iterative-penalty-simple
:
:  \begin{alignedat}{2}
:  {\rm ciwip}\left(P, f, r, n\right) = P {\left(\frac{r}{n} + 1\right)}^{n} - \frac{{\left(n \left(\frac{n + r}{n}\right)^{n} - n\right)} f}{r}
:  \end{alignedat}

#+MACRO: compound-interest-with-iterative-penalty-simple (eval (latex-display-wrap (org-sbe compound-interest-with-iterative-penalty-simple)))

{{{compound-interest-with-iterative-penalty-simple()}}}

With this expression we can now model the behavior of a manual compounding
earning protocol with a compounding schedule of src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(n))}. With this model,
let's try to gain some insight into how they work with some visualizations. This
will allow us to understand them better before we find the best schedule.

* Understanding via visualization ðŸ“ˆ

It seems most reasonable to start with a 2D plot dependent on
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} because it's the only parameter that we can
control once we put in a deposit. Holding all the other parameters constant
using some arbitrary values, we get the following plot:

#+NAME: ciwip-func-def
#+HEADER: :exports none :results output
#+begin_src python :dir (org-sbe container-dir-str) :session
  def optimal_compound_interest_with_iterative_penalty(P_, f_, r_, astype=float):

      ## Formula for ciwip
      P, f, r, i, n = var("P f r i n")
      compound_interest = ( P * ( 1 + ( r / n ) ) ** n )
      iterative_penalty = ( f * sum( (1 + (r / n))**i , i, 0, n-1) )
      compound_interest_with_iterative_penalty = compound_interest - iterative_penalty

      ## Compute ciwip from params and minimize
      ciwip_min_ = -1.0 * compound_interest_with_iterative_penalty.substitute(P=P_, f=f_, r=r_)
      ciwip_min_result = sage.numerical.optimize.minimize(
          ciwip_min_,
          [1e-10],
          algorithm='bfgs',
          gradient=ciwip_min_.diff()
      )
      if astype == float:
          return ciwip_min_result[0]
      elif astype == int:
          if compound_interest_with_iterative_penalty.substitute(P=P_, f=f_, r=r_, n=floor(ciwip_min_result[0])) > \
              compound_interest_with_iterative_penalty.substitute(P=P_, f=f_, r=r_, n=ceil(ciwip_min_result[0])):
              return floor(ciwip_min_result[0])
          else:
              return ceil(ciwip_min_result[0])
      else:
          raise Exception(f"{astype} unsupported")
#+end_src

#+RESULTS: ciwip-func-def

#+NAME: compound-interest-with-iterative-penalty-plot
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  from spb.backends.plotly import PB
  from spb import plot as spb_plot

  title = "Compound interest with iterative penalty"
  filename = f'{title.lower().replace(" ","-")}-plot.png'
  params = {
      P: 100,
      r: 0.8,
      f: 4
  }
  upper_bound = params[P] * params[r] / params[f]
  params_by_str = {str(k): v for k,v in params.items()}
  params_tex_str = ' \ | \ '.join(f'{latex(p)}={v}' for p,v in params.items())
  pl = spb_plot(
      (compound_interest_with_iterative_penalty.subs(params), (n, 0, upper_bound + (upper_bound * 0.1))),
      title=f"$\\text{{{title}}} \\\\ {{{params_tex_str}}}$",
      show=False,
      use_latex=True,
      legend=False,
      theme="plotly",
      xlabel=f"${n}$",
      ylabel=f"$ciwip$",
      backend=PB
  )
  pl._update_layout()
  pl._fig.update_layout(
      title_x=0.09,
      margin=dict(
          l=70,
          r=50,
          b=70,
          t=100,
          pad = 4
      )
  )
  pl._process_series(pl._series)
  pl._fig.write_image(filename)
  print(f"Filename: {filename}")
#+END_SRC

#+RESULTS: compound-interest-with-iterative-penalty-plot
: /tmp/python-fGxzl7:13: DeprecationWarning:
:
: invalid escape sequence \
:
: Filename: compound-interest-with-iterative-penalty-plot.png

#+CAPTION: 2D view of compound interest with iterative penalties
[[./compound-interest-with-iterative-penalty-plot.png]]

With this 2D view we can now get a better understanding of what optimal
compounding really means.

The first intuition we can take away is that as we tend src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex_right(latex(n),
latex(oo)))} {{{results($n \rightarrow +\infty$)}}} we see that our output value
tends towards negative infinity meaning we lose more than we are gaining (which
we don't want). However, there is an inflection point (around src_python[:results
output :session :dir (org-sbe
container-dir-str)]{print(latex(n==round(optimal_compound_interest_with_iterative_penalty(params_by_str['P'],
params_by_str['f'], params_by_str['r']), 2)))} {{{results($n = 2.79$)}}}) where
we make *more* than we lose. This means that by compounding at the right
frequency, the accrued rewards are greater than the fees we need to pay to claim
them.

Now we can return to our original question: "how do we spend the least to make
the most?". The answer we can infer from this plot for manual compounding is
"choose the optimal src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} {{{results($n$)}}}".

#+NAME: compound-interest-with-iterative-penalty-zero-limit-analysis
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_center(
          latex_lim(
              latex(
                  ciwip(P,r,f,n).derivative(n) == \
                  limit(compound_interest_with_iterative_penalty.derivative(n),n=oo)
              ),
              latex(n),
              latex(oo)
          )
      )
  )
#+END_SRC

#+RESULTS: compound-interest-with-iterative-penalty-zero-limit-analysis
:
:  \begin{alignedat}{2}
:  \lim\limits_{ n \rightarrow +\infty } \frac{\partial}{\partial n}{\rm ciwip}\left(P, f, r, n\right) = -\frac{f e^{r} - f}{r}
:  \end{alignedat}

#+MACRO: compound-interest-with-iterative-penalty-zero-limit-analysis (eval (latex-display-wrap (org-sbe compound-interest-with-iterative-penalty-zero-limit-analysis)))

#+begin_quote
*Aside* - Something interesting to note is that as we tend src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex_right(latex(n),
latex(oo)))} it looks like our function starts to become linear. We can prove
this by taking the limit of the derivative of our function. We can see it's
independent of src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} {{{results($n$)}}} meaning that even though
compounding to infinity means we will keep losing, we will eventually lose at a
constant rate.

{{{compound-interest-with-iterative-penalty-zero-limit-analysis()}}}
#+end_quote

** Homogenization

For the example above we used fixed parameters, but what if we changed them to
be higher or lower? How would our plot change? Would we still see the same
shape? To learn a little more about the shape of this function, let's unify all
the parameters we can't control under some var src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(C))} {{{results($C$)}}}
and plot what we have left in 3D.

Doing so will give us the following expression:

#+NAME: homogenized-compound-interest-with-iterative-penalty
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  C = var('C')
  homogenized_compound_interest_with_iterative_penalty = compound_interest_with_iterative_penalty.substitute(P=C, f=C, r=C)
  const_sympy = homogenized_compound_interest_with_iterative_penalty._sympy_()
  const_sympy_vars = {str(i): i for i in const_sympy.free_symbols}
  print(latex_center(latex(homogenized_compound_interest_with_iterative_penalty)))
#+END_SRC

#+RESULTS: homogenized-compound-interest-with-iterative-penalty
:
:  \begin{alignedat}{2}
:  -n \left(\frac{C + n}{n}\right)^{n} + C {\left(\frac{C}{n} + 1\right)}^{n} + n
:  \end{alignedat}

#+MACRO: homogenized-compound-interest-with-iterative-penalty (eval (latex-display-wrap (org-sbe homogenized-compound-interest-with-iterative-penalty)))

{{{homogenized-compound-interest-with-iterative-penalty()}}}

Visualizing this expression gives us the following plot:

#+NAME: homogenized-compound-interest-with-iterative-penalty-plot
#+HEADER: :exports none :results output
#+begin_src python :dir (org-sbe container-dir-str) :session
  import numpy as np
  import plotly.graph_objects as go
  from plotly.subplots import make_subplots

  def get_plane(M, v, xx, yy, zz):

      # M point contained by the plane
      # v direction included in plane (orthogonal to w=[0, 0, 1])
      x0, y0, _= M
      a, b, _= v

      if a == 0 and b != 0:
          Y, Z = np.meshgrid(yy, zz)
          X = x0*np.ones(Y.shape)
      elif a != 0 and b==0:
          X, Z = np.meshgrid(xx, zz)
          Y = y0*np.ones(X.shape)
      else:
          X, Z = np.meshgrid(xx, zz)
          Y = y0+b*(X-x0)/a
      return X, Y, Z


  # define xy mesh and z func output
  xx = np.linspace(2, 12, 50)
  yy = np.linspace(2, 12, 50)
  x,y = np.meshgrid(xx, yy)
  fff = sympy.lambdify((const_sympy_vars["n"], const_sympy_vars["C"]), const_sympy, "numpy")
  z = fff(x, y)
  zz = np.linspace(z.min(), z.max(), 50)

  M = [0, 11, 0]  # a point in the plane
  v = [1, 0, 0] # a direction contained in the plane
  X, Y, Z =  get_plane(M, v, xx, yy, zz)

  fig = make_subplots(
       rows=1, cols=1,
       horizontal_spacing=0.1)
  fig.add_trace(go.Surface(x=x,
                           y=y,
                           z=z,
                           colorscale="Viridis",
                           lighting=dict(diffuse=0.9),
                           showscale=False))
  fig.add_trace(go.Surface(x=X, y=Y, z=Z,
                           colorscale= [[0, "rgb(254, 254, 254)"],
                                        [1, "rgb(254, 254, 254)"]],
                           showscale=False,
                           lighting=dict(diffuse=0.9),
                           opacity=0.3))
  fig.update_layout(
      scene_camera=dict(
        eye=dict(x=2, y=2.5, z=2.3)
      ),
      margin=dict(t=0, r=0, l=0, b=0),
      width=600, height=600, yaxis = {"domain":  [0, 0.85]},
      scene = dict(
                    xaxis_title='n',
                    yaxis_title='C',
                    zaxis_title='$')
  )
  fig.update_xaxes(autorange="reversed")
  fig.update_xaxes(range=[12, 1])
  fig.update_scenes(xaxis_autorange="reversed")
  fig.update_scenes(yaxis_autorange="reversed")
  fig.write_image("homogenized-compound-interest-with-iterative-penalty-plot.png")
  print("done!")
#+end_src

#+RESULTS: homogenized-compound-interest-with-iterative-penalty-plot
: done!

#+CAPTION: A surface 3D plot of homogenized compound interest with iterative penalties
[[./homogenized-compound-interest-with-iterative-penalty-plot.png]]

The interesting thing we can observe is that if we hold the variables we can't
control constant (via src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(C))} {{{results($C$)}}}) and represent some
choice src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(C))} by slicing the space with a plane (shown by
the slightly opaque vertical plane), the corresponding cross section is the
space of possible results of our balance as a consequence of choosing some
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))}. Looking closely, there seems to be a
similar shape between the intersection and the 2D plot, and if we slide the
opaque plane up and down the src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(C))} axis, the shape seems consistent. However,
this empirical observation doesn't prove anything. Instead, in search of our
optimal src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))}, let's explore some of the mathematical
properties of our problem.

* In search of optimality â›°

We showed in the previous section that when we chose some fixed parameters for
our src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip))} {{{results($ciwip$)}}} function, there was an
optimal src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} that enables us to earn more than we
lose. This is obviously an ideal case which we want to happen all the time!
Unfortunately, in reality, our "fixed" parameters aren't so "fixed" and fees and
APRs can change by the second. What we really want to know is: for any
reasonable set of parameters, can we find the optimal number of compounds that
gets us a balance greater than what we started with?

** Using the gradient

One initial approach we can take is to use the gradient. If we find where the
gradient is equal to zero, then we can find the extrema of our function which
will allow us to find our inflection point and optimal number of
compounds. Unfortunately, this isn't really tractable so we will need to find
another way.

#+NAME: gradient-compound-interest-with-iterative-penalty
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_center(
          latex(
              compound_interest_with_iterative_penalty.diff(n).simplify() == \
              ciwip(P,r,f,n).derivative(n)
          )
      )
  )
#+END_SRC

#+RESULTS: gradient-compound-interest-with-iterative-penalty
:
:  \begin{alignedat}{2}
:  -P {\left(\frac{r}{n} + 1\right)}^{n} {\left(\frac{r}{n {\left(\frac{r}{n} + 1\right)}} - \log\left(\frac{r}{n} + 1\right)\right)} + \frac{{\left({\left(\frac{n^{2} {\left(\frac{n + r}{n^{2}} - \frac{1}{n}\right)}}{n + r} - \log\left(\frac{n + r}{n}\right)\right)} n \left(\frac{n + r}{n}\right)^{n} - \left(\frac{n + r}{n}\right)^{n} + 1\right)} {f_{gas}}}{r} = \frac{\partial}{\partial n}{\rm ciwip}\left(P, r, {f_{gas}}, n\right)
:  \end{alignedat}

#+MACRO: gradient-compound-interest-with-iterative-penalty (eval (latex-display-wrap (org-sbe gradient-compound-interest-with-iterative-penalty)))

{{{gradient-compound-interest-with-iterative-penalty()}}}

** Avoiding losses

Another direction we can take is to simplify our problem by finding all the
places where we lose more than we gain, and ignoring them.

We know that the space of possible compounds is from src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex_right(latex(0),
latex(oo)))} {{{results(0 \rightarrow +\infty)}}} and we've already established
that as we compound more and more we get diminishing returns, and eventually
substantial losses. To avoid these losses, we need to see where
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip(P,r,f,n)<P))} {{{results(${\rm
ciwip}\left(P\, r\, f\, n\right) < P$)}}}. We can observe from our 2D graph of
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip))} that src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(P))} is intersected
twice, first at src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(0))} {{{results($0$)}}} and second at
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n==(P*r/f).subs(params)))} {{{results($n =
20.0$)}}}. Now based on what we know about this function, it makes sense that
there will always be two points where src_python[:results output :session :dir
(org-sbe container-dir-str)]{print(latex(ciwip(P,r,f,n)==P))}, one when we don't
compound at all, and one when we are compounding too much to the point where we
end up "net even." This second "net even" point is important because with it we
can show that compounding beyond it will always lead to losses. To find this
point we can take src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip(P,r,f,n)==P))}, and simply solve for
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))}. Doing so gets us the expression.

#+NAME: net-even
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  net_even_n = solve((compound_interest_with_iterative_penalty==P), n)[0]
  print(latex_center(latex(net_even_n)))
#+END_SRC

#+RESULTS: net-even
:
:  \begin{alignedat}{2}
:  n = \frac{P r}{f}
:  \end{alignedat}

#+MACRO: net-even (eval (latex-display-wrap (org-sbe net-even)))

{{{net-even()}}}

This means all we need to do is show that if we compound beyond this "net
even" point with some positive src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(eps))} {{{results(${\epsilon}$)}}}, we will
always get less than our initial balance src_python[:results output :session
:dir (org-sbe container-dir-str)]{print(latex(P))}. If we put this into an
expression, we get:

#+NAME: net-loss
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  eps = var("eps", latex_name="\\epsilon")
  print(latex_center(latex(ciwip(P,r,f,net_even_n.rhs() + eps) < P)))
#+END_SRC

#+RESULTS: net-loss
:
:  \begin{alignedat}{2}
:  {\rm ciwip}\left(P, f, r, {\epsilon} + \frac{P r}{f}\right) < P
:  \end{alignedat}

#+MACRO: net-loss (eval (latex-display-wrap (org-sbe net-loss)))

{{{net-loss()}}}

And if we follow the substitution and replacement we get the expression:

#+NAME: net-loss-proven
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  eq = (compound_interest_with_iterative_penalty.subs({n:(P*r/f) + eps}) - P).simplify_full()
  reformatted_eq = (-(eps*f/r)) * ( ((eps*f + (P + f)*r)/(eps*f + P*r))**(eps + P*r/f) - 1 )
  eeqq = (-(eps*f/r)).mul(1, hold=True) * (((eps*f + (P + f)*r)/(eps*f + P*r))**(eps + P*r/f) - 1).mul(1, hold=True)
  assert bool(eeqq - reformatted_eq ) == 0
  print(latex_center(latex(eeqq < 0)))
#+END_SRC

#+RESULTS: net-loss-proven
:
:  \begin{alignedat}{2}
:  \left(-\frac{{\epsilon} f}{r}\right) {\left(\left(\frac{{\epsilon} f + {\left(P + f\right)} r}{{\epsilon} f + P r}\right)^{{\epsilon} + \frac{P r}{f}} - 1\right)} < 0
:  \end{alignedat}

#+MACRO: net-loss-proven (eval (latex-display-wrap (org-sbe net-loss-proven)))

{{{net-loss-proven()}}}

This expression will always hold true as long as all the components are positive
real values (which we've already established is true in the framing of our
problem). This is due to the fact that the left hand component will always be
negative, and the right hand component will always be positive. This means the
result will always be negative.

This allows us to conclude that compounding greater than src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex(net_even_n.rhs() +
eps))} for any src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(eps>0))} we will always end up with less than
our original balance.

Now we know that our optimal value must lie in between src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex(0))}
{{{results($0$)}}} and src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(net_even_n.rhs()))} {{{results($\frac{P
r}{f}$)}}}, let's try to see if we will always be able to find this optimal
point.

** Concavity

Now that we know our optimal value is bounded, instead of trying to find a
closed form way of getting the maximum of our function, maybe we can search for
it. The only problem we have now is how do we know our optimal value is easily
findable? Luckily there is a property we can try to prove about our function to
make finding it easier. The most ideal property we would want to prove is
concavity.

If we can show that our function is concave, then we will know two important things:

1. All local maxima are global maxima
2. An optimizer will find a local maxima

In order to find out if this function is truly concave, we can leverage [[https://en.wikipedia.org/wiki/Jensen%27s_inequality][Jensen's
inequality]] and check if it is true in all cases.

#+NAME: jensins-inequality
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  def jensins_inequality(func=None, a=None, b=None):
      if func is None:
          func = function("g")
      if a is None:
          a = var("x_1")
      if b is None:
          b = var("x_2")

      lam = var('lam', latex_name="\\lambda")
      return \
          func(lam * a + abs(lam - 1) * b) \
          > \
          lam * func(a) + abs(lam - 1) * func(b)

  print(
      latex_center(
          latex(jensins_inequality())
      )
  )
#+END_SRC

#+RESULTS: jensins-inequality
:
:  \begin{alignedat}{2}
:  g\left({\lambda} x_{1} + x_{2} {\left| {\lambda} - 1 \right|}\right) > {\lambda} g\left(x_{1}\right) + {\left| {\lambda} - 1 \right|} g\left(x_{2}\right)
:  \end{alignedat}

#+MACRO: jensins-inequality (eval (latex-display-wrap (org-sbe jensins-inequality)))

{{{jensins-inequality()}}}

If we substitute our function into Jensen's inequality and supply our bounds
(ignoring everything but the src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} parameter) we get:

#+NAME: ciwip-jensins-inequality
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_center(
          latex(jensins_inequality(ciwip, 0, (P*r)/f))
      )
  )
#+END_SRC

#+RESULTS: ciwip-jensins-inequality
:
:  \begin{alignedat}{2}
:  {\rm ciwip}\left(\frac{P r {\left| {\lambda} - 1 \right|}}{f}\right) > {\lambda} {\rm ciwip}\left(0\right) + {\left| {\lambda} - 1 \right|} {\rm ciwip}\left(\frac{P r}{f}\right)
:  \end{alignedat}

#+MACRO: ciwip-jensins-inequality (eval (latex-display-wrap (org-sbe ciwip-jensins-inequality)))

{{{ciwip-jensins-inequality()}}}

Substituting further and reducing we get the expression:

#+NAME: substituted-ciwip-jensins-inequality
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  a = 0
  b = P*r/f
  c = compound_interest_with_iterative_penalty
  lam = var('lam', latex_name="\\lambda")
  c_j = \
    ( c.subs({n: (lam * a) + (abs(lam-1) * b)}) - P).simplify_full() \
    > \
    ( (lam * (P - P)) + (abs(lam-1) * (P-P)) ).simplify_full()

  alpha = -(P*abs(lam - 1) - P).mul(1, hold=True)
  beta = ((c_j.lhs() - c_j.rhs())/(-(P*abs(lam - 1) - P))).simplify_full()
  print(
      latex_center(
          latex((alpha * beta) > 0)
      )
  )
#+END_SRC

#+RESULTS: substituted-ciwip-jensins-inequality
:
:  \begin{alignedat}{2}
:  -{\left(P {\left| {\lambda} - 1 \right|} - P\right)} {\left(\left(\frac{P {\left| {\lambda} - 1 \right|} + {f_{gas}}}{P {\left| {\lambda} - 1 \right|}}\right)^{\frac{P r {\left| {\lambda} - 1 \right|}}{{f_{gas}}}} - 1\right)} > 0
:  \end{alignedat}

#+MACRO: substituted-ciwip-jensins-inequality (eval (latex-display-wrap (org-sbe substituted-ciwip-jensins-inequality)))

{{{substituted-ciwip-jensins-inequality()}}}

This final inequality will tell us if our function src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(ciwip))} is concave or
not. It may not seem like it right away but this inequality will always be true
if our components are positive real values. Let's break down this expression a
bit more to see why.

#+NAME: vars-decomposed-ciwip-jensins-inequality
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  alph = var('alph', latex_name="\\alpha")
  bet = var('bet', latex_name="\\beta")
#+END_SRC

#+RESULTS: vars-decomposed-ciwip-jensins-inequality

First let's decompose the left hand side of our expression into two components
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(alph))} and src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(bet))} as follows:

#+NAME: decomposed-ciwip-jensins-inequality
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  print(
      latex_centers(
          latex(alpha.unhold().simplify() == alph),
          latex(beta == bet),
          latex((alph * bet) > 0)
      )
  )
#+END_SRC

#+RESULTS: decomposed-ciwip-jensins-inequality
:
:  \begin{alignedat}{2}
:  -P {\left| {\lambda} - 1 \right|} + P = {\alpha} \\ \left(\frac{P {\left| {\lambda} - 1 \right|} + f}{P {\left| {\lambda} - 1 \right|}}\right)^{\frac{P r {\left| {\lambda} - 1 \right|}}{f}} - 1 = {\beta} \\ {\alpha} {\beta} > 0
:  \end{alignedat}

#+MACRO: decomposed-ciwip-jensins-inequality (eval (latex-display-wrap (org-sbe decomposed-ciwip-jensins-inequality)))

{{{decomposed-ciwip-jensins-inequality()}}}

Looking at our decomposition we can first observe that src_python[:results
output :session :dir (org-sbe container-dir-str)]{print(latex(alph>0))} because
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(P>(P*abs(lam - 1))))} {{{results(P > P {\left|
{\lambda} - 1 \right|})}}}.

We can also infer that src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(bet>0))}.

Since src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(((P*abs(lam - 1))+f) > (P*abs(lam - 1))))}
{{{results($P {\left| {\lambda} - 1 \right|} + {f_{gas}} > P {\left| {\lambda} -
1 \right|}$)}}}, we know the base of the exponent is greater than 1. We also
know that any number greater than 1 raised to a positive power will also be
greater than 1. This means that src_python[:results output :session :dir
(org-sbe container-dir-str)]{print(latex(bet))} must be positive.

Now that we have inferred that src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(alph))} and src_python[:results output :session
:dir (org-sbe container-dir-str)]{print(latex(bet))} are both positive we can
finally affirm that src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex((alph*bet)>0))} must also be true!

Finally, since we have shown that src_python[:results output :session :dir
(org-sbe container-dir-str)]{print(latex((alph*bet)>0))} must be true, we have
shown that Jensen's inequality must always be true, and that our function is
always concave. Knowing this, and being paired with the knowledge of a bound on
our search space, we can reframe our formula as an optimization problem:

#+NAME: optimization-ciwip
#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  n_star = var("n_star", latex_name="n^\\prime")
  P_star = var("P_star", latex_name="P_{n^\\prime}")
  ubound = P*r/f
  katex_str = f"""\\argmax_{{ {latex(n_star)} \\isin \\mathbb{{Z}}^+ < {latex(ubound)} }} {latex(ciwip(P,r,f,n_star) == P_star)}"""
  print(latex_center(katex_str))
#+END_SRC

#+RESULTS: optimization-ciwip
:
:  \begin{alignedat}{2}
:  \argmax_{ {n^\prime} \isin \mathbb{Z}^+ < \frac{P r}{{f_{gas}}} } {\rm ciwip}\left(P, r, {f_{gas}}, {n^\prime}\right) = {P_{n^\prime}}
:  \end{alignedat}

#+MACRO: optimization-ciwip (eval (latex-display-wrap (org-sbe optimization-ciwip)))

{{{optimization-ciwip()}}}

In this framing, src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n_star))} represents our optimal
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(n))} and since we know our problem is convex, we
know we will always find it. Using our optimal src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(n_star))} allows us now
to predict future earnings for src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip))} with the optimal compounding schedule.

#+begin_quote
*Aside* - You will notice that we are optimizing src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(n_star))} over the
integers and not real values. We have to do this as there is no way we can
compound a "fractional" number of times. However, we can do this and preserve
concavity (from [[https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf][section 3.2.2 of Stephen Boyd's convex optimization book]])
if we say the integers are a "subset" of the reals.
#+end_quote


* Compare and contrast

Now that we have an expression to predict future earnings for optimal
src_python[:results output :session :dir (org-sbe
container-dir-str)]{print(latex(ciwip))}, which models manual compounding
earning protocols, and an expression for auto compounding earning protocols,
let's see how they compare against one another with some hand-picked parameters:

#+HEADER: :exports none :results output
#+BEGIN_SRC python :dir (org-sbe container-dir-str) :session
  from spb.backends.plotly import PB
  from spb import plot as spb_plot

  title = "Earning protocols over time"
  filename = f'{title.lower().replace(" ","-")}-plot.png'
  params = {
      P: 1000,
      r: 0.8,
      f: 0.03
  }
  params_by_str = {str(k): v for k,v in params.items()}
  params_tex_str = ' \ | \ '.join(f'{latex(p)}={v}' for p,v in params.items())

  def ciwip_over_time(input_params):

      # Get params for calculating the range of balances
      if n not in input_params:
          opt_n = optimal_compound_interest_with_iterative_penalty(
              params[P],
              params[f],
              params[r],
              astype=int
          )
      else:
          opt_n = input_params[n]

      t_diff = 1.0 / opt_n
      ranges = []
      P_init = input_params[P]
      compound = lambda P_, r_, t_, f_: (P_ + (P_*r_*t_) - f_)

      # Calculate the balance for each compounding instance based
      # on the optimal number of compounds
      for i in range(1, opt_n+5):
          range_i = (round((t_diff * i) - t_diff, 4) , round(t_diff * i, 4))
          ranges.append((range_i, P_init))
          P_init = compound(P_init, r, t, f).subs({**input_params, P: P_init, t:t_diff})
      return piecewise(ranges, var=t)

  compound_interest_with_auto_fee = ( P * ( 1 + ( r / n ) - (f_p/n) ) ** (n*t) )
  axis_range = (t, 0.6, 1.01)
  pl = spb_plot(
      (compound_interest_with_auto_fee.subs({**params, n: 1e5, f_p: 0}),
       axis_range,
       "$Continuous \ compounding \ interest$"),
      (ciwip_over_time(params),
       axis_range,
       "$Optimal \ ciwip$"),
      (compound_interest_with_auto_fee.subs({**params, n: 5000*365, f_p:0.02}),
       (t, 0.6, 1.01),
       "$2\% \ auto \ compounding \ fee$"),
      title=f"$\\text{{{title}}} \\\\ {{{params_tex_str}}}$",
      show=False,
      process_piecewise=False,
      use_latex=True,
      legend=True,
      theme="plotly",
      xlabel=f"$time \ (years)$",
      ylabel=f"$Balance \ (tokens)$",
      backend=PB
  )
  pl._update_layout()
  pl._fig.update_layout(
      title_x=0.09,
      margin=dict(
          l=70,
          r=50,
          b=70,
          t=100,
          pad = 4
      ),
      legend=dict(
          yanchor="top",
          y=0.99,
          xanchor="left",
          x=0.01
      )
  )
  pl._process_series(pl._series)
  pl._fig.write_image(filename)
  print(f"Filename: {filename}")
#+END_SRC

#+RESULTS:
#+begin_example
/tmp/python-OGzUt9:12: DeprecationWarning:

invalid escape sequence \

/tmp/python-OGzUt9:45: DeprecationWarning:

invalid escape sequence \

/tmp/python-OGzUt9:48: DeprecationWarning:

invalid escape sequence \

/tmp/python-OGzUt9:51: DeprecationWarning:

invalid escape sequence \%

/tmp/python-OGzUt9:58: DeprecationWarning:

invalid escape sequence \

/tmp/python-OGzUt9:59: DeprecationWarning:

invalid escape sequence \

Filename: earning-protocols-over-time-plot.png
#+end_example

#+CAPTION: Different earning protocols modeled over time
[[./earning-protocols-over-time-plot.png]]

The interesting thing to take away from this plot is that given the following
set of parameters, manual compounding via optimal src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(ciwip))} performs better
than the auto compounding counterpart (with continuous compound interest
performing the best). This means that if we were to assume, at the start, that
auto compounding earning protocols were better and invested in them, we could be
missing out on potential profits by not using optimal src_python[:results output
:session :dir (org-sbe container-dir-str)]{print(latex(ciwip))}. However, if we
increased the gas fee, our auto compounding variety would perform better (we
will save the theory for which scenarios cause one to perform better over the
other for another post).

Armed with the tools to model earnings for both compounding types, we can now
make an informed decision about maximizing our profits.

* Future directions

Despite the depth of this post in exploring earning protocols, we only scratched
the surface as there are plenty of potentially interesting areas to explore:

1. Statistically representing earning protocol parameters:

   As mentioned earlier in this post, fees and APRs can change by the second
   based on a myriad of factors. If we were to represent these parameters as
   distributions, how would our compounding schedule or future earnings change?
   How could we use outside knowledge to update our hypotheses about this
   problem?

2. Earning protocol rebalancing strategies:

   There are many earning protocols to choose from. How should we associate risk
   with them? When do we leave one for another? Where do we redirect streams of
   earnings?

* Conclusion

The world of defi and cryptocurrency continues to fascinate me as new economic
experiments and protocols get launched every day. Despite the negative press, I
truly believe these experiments will yield novel results and change the way we
move value between one another. It also could all go to zero, but I'll enjoy the
ride either way.

I hope you enjoyed and learned something new ðŸ–

* Environment teardown                                             :noexport:

#+HEADER: :exports none
#+begin_src sh :var NAME=(org-table-get-constant "container_name") :var SHUTDOWN=(org-table-get-constant "shutdown-env")
# [[ $SHUTDOWN ]] && podman kill $NAME; podman rm $NAME
#+end_src

#+RESULTS:
| compounder                                                       |
| 514dc2da37e88051d3bd8417bb6a9dc5879c43f60c53301fe2bc1f594c33d587 |
